"""
Functions and job classes for sample analysis.

"""
import os
import shlex

import aiofiles

import virtool.caches.db
import virtool.history.db
import virtool.jobs.analysis
import virtool.jobs.job
import virtool.jobs.utils
import virtool.otus.utils
import virtool.pathoscope
import virtool.samples.db
import virtool.samples.utils

TRIMMING_PROGRAM = "skewer-0.2.2"


async def map_default_isolates(job: virtool.jobs.job.Job):
    """
    Using ``bowtie2``, maps reads to the main otu reference. This mapping is used to identify candidate otus.

    TODO: Will be step in workflow-pathoscope

    """
    command = [
        "bowtie2",
        "-p", str(job.proc),
        "--no-unal",
        "--local",
        "--score-min", "L,20,1.0",
        "-N", "0",
        "-L", "15",
        "-x", job.params["index_path"],
        "-U", ",".join(job.params["read_paths"])
    ]

    to_otus = set()

    async def stdout_handler(line):
        line = line.decode()

        if line[0] == "#" or line[0] == "@":
            return

        fields = line.split("\t")

        # Bitwise FLAG - 0x4: segment unmapped
        if int(fields[1]) & 0x4 == 4:
            return

        ref_id = fields[2]

        if ref_id == "*":
            return

        # Skip if the p_score does not meet the minimum cutoff.
        if virtool.pathoscope.find_sam_align_score(fields) < 0.01:
            return

        to_otus.add(ref_id)

    await job.run_subprocess(command, stdout_handler=stdout_handler)

    job.intermediate["to_otus"] = to_otus


async def generate_isolate_fasta(job: virtool.jobs.job.Job):
    """
    Identifies otu hits from the initial default otu mapping.

    TODO: In virtool-workflow, this needs to be reimplemented such that it is not necessary for the steps to access the
          DB directly. On thought is downloading the entire reference and provided methods on a `references` that allow
          generating and isolate Bowtie2 index on the fly.

    """
    fasta_path = os.path.join(
        job.params["temp_analysis_path"],
        "isolate_index.fa"
    )

    ref_lengths = dict()

    sequence_otu_map = job.params["sequence_otu_map"]

    # The ids of OTUs whose default sequences had mappings.
    otu_ids = {sequence_otu_map[sequence_id] for sequence_id in job.intermediate["to_otus"]}

    app_dict = {
        "db": job.db,
        "settings": job.settings
    }

    # Get the database documents for the sequences
    async with aiofiles.open(fasta_path, "w") as f:
        # Iterate through each otu id referenced by the hit sequence ids.
        for otu_id in otu_ids:
            otu_version = job.params["manifest"][otu_id]

            _, patched, _ = await virtool.history.db.patch_to_version(
                app_dict,
                otu_id,
                otu_version
            )

            for isolate in patched["isolates"]:
                for sequence in isolate["sequences"]:
                    await f.write(f">{sequence['_id']}\n{sequence['sequence']}\n")
                    ref_lengths[sequence["_id"]] = len(sequence["sequence"])

    del job.intermediate["to_otus"]

    job.intermediate["ref_lengths"] = ref_lengths


async def build_isolate_index(job: virtool.jobs.job.Job):
    """
    Build an index with ``bowtie2-build`` from the FASTA file generated by
    :meth:`Pathoscope.generate_isolate_fasta`.

    TODO: In virtool-workflow, this needs to be reimplemented such that it is not necessary for the steps to access the
          DB directly. On thought is downloading the entire reference and provided methods on a `references` that allow
          generating and isolate Bowtie2 index on the fly.

    """
    command = [
        "bowtie2-build",
        "--threads", str(job.proc),
        os.path.join(job.params["temp_analysis_path"], "isolate_index.fa"),
        os.path.join(job.params["temp_analysis_path"], "isolates")
    ]

    await job.run_subprocess(command)


async def map_isolates(job: virtool.jobs.job.Job):
    """
    Using ``bowtie2``, map the sample reads to the index built using :meth:`.build_isolate_index`.

    TODO: Will remain a step of workflow-pathoscope

    """
    command = [
        "bowtie2",
        "-p", str(job.proc - 1),
        "--no-unal",
        "--local",
        "--score-min", "L,20,1.0",
        "-N", "0",
        "-L", "15",
        "-k", "100",
        "--al", os.path.join(job.params["temp_analysis_path"], "mapped.fastq"),
        "-x", os.path.join(job.params["temp_analysis_path"], "isolates"),
        "-U", ",".join(job.params["read_paths"])
    ]

    async with aiofiles.open(os.path.join(job.params["temp_analysis_path"], "to_isolates.vta"), "w") as f:
        async def stdout_handler(line, p_score_cutoff=0.01):
            line = line.decode()

            if line[0] == "@" or line == "#":
                return

            fields = line.split("\t")

            # Bitwise FLAG - 0x4 : segment unmapped
            if int(fields[1]) & 0x4 == 4:
                return

            ref_id = fields[2]

            if ref_id == "*":
                return

            p_score = virtool.pathoscope.find_sam_align_score(fields)

            # Skip if the p_score does not meet the minimum cutoff.
            if p_score < p_score_cutoff:
                return

            await f.write(",".join([
                fields[0],  # read_id
                ref_id,
                fields[3],  # pos
                str(len(fields[9])),  # length
                str(p_score)
            ]) + "\n")

        await job.run_subprocess(command, stdout_handler=stdout_handler)


async def map_subtraction(job: virtool.jobs.job.Job):
    """
    Using ``bowtie2``, map the reads that were successfully mapped in :meth:`.map_isolates` to the subtraction host
    for the sample.

    TODO: Need `subtractions` fixture. This function will remain a step of workflow-pathoscope

    """
    command = [
        "bowtie2",
        "--local",
        "-N", "0",
        "-p", str(job.proc - 1),
        "-x", shlex.quote(job.params["subtraction_path"]),
        "-U", os.path.join(job.params["temp_analysis_path"], "mapped.fastq")
    ]

    to_subtraction = dict()

    async def stdout_handler(line):
        line = line.decode()

        if line[0] == "@" or line == "#":
            return

        fields = line.split("\t")

        # Bitwise FLAG - 0x4 : segment unmapped
        if int(fields[1]) & 0x4 == 4:
            return

        # No ref_id assigned.
        if fields[2] == "*":
            return

        to_subtraction[fields[0]] = virtool.pathoscope.find_sam_align_score(fields)

    await job.run_subprocess(command, stdout_handler=stdout_handler)

    job.intermediate["to_subtraction"] = to_subtraction


async def subtract_mapping(job: virtool.jobs.job.Job):
    """
    Use code from the Pathoscope2 package to subtract subtraction-mapped reads that had a lower scored mapping to the
    OTU reference.

    TODO: Will remain step of workflow-pathoscope.

    :param job:

    """
    target_path = os.path.join(
        job.params["temp_analysis_path"],
        "to_isolates.vta"
    )

    output_path = os.path.join(
        job.params["temp_analysis_path"],
        "subtracted.vta"
    )

    subtracted_count = await virtool.pathoscope.subtract(
        target_path,
        output_path,
        job.intermediate["to_subtraction"]
    )

    await job.run_in_executor(
        virtool.pathoscope.replace_after_subtraction,
        output_path,
        target_path
    )

    del job.intermediate["to_subtraction"]

    job.results["subtracted_count"] = subtracted_count


async def pathoscope(job: virtool.jobs.job.Job):
    """
    Run the Pathoscope reassignment algorithm. Tab-separated output is written to ``pathoscope.tsv``. Results are
    also parsed and saved to :attr:`intermediate`.

    TODO: Will remain step of workflow-pathoscope

    """
    vta_path = os.path.join(
        job.params["temp_analysis_path"],
        "to_isolates.vta"
    )

    reassigned_path = os.path.join(
        job.params["temp_analysis_path"],
        "reassigned.vta"
    )

    pathoscope_results = await job.run_in_executor(
        run_patho,
        vta_path,
        reassigned_path
    )

    (
        best_hit_initial_reads,
        best_hit_initial,
        level_1_initial,
        level_2_initial,
        best_hit_final_reads,
        best_hit_final,
        level_1_final,
        level_2_final,
        init_pi,
        pi,
        refs,
        reads
    ) = pathoscope_results

    read_count = len(reads)

    report = await job.run_in_executor(
        virtool.pathoscope.write_report,
        os.path.join(job.params["temp_analysis_path"], "report.tsv"),
        pi,
        refs,
        read_count,
        init_pi,
        best_hit_initial,
        best_hit_initial_reads,
        best_hit_final,
        best_hit_final_reads,
        level_1_initial,
        level_2_initial,
        level_1_final,
        level_2_final
    )

    job.intermediate["coverage"] = await job.run_in_executor(
        virtool.pathoscope.calculate_coverage,
        reassigned_path,
        job.intermediate["ref_lengths"]
    )

    job.results.update({
        "ready": True,
        "read_count": read_count,
        "results": list()
    })

    for ref_id, hit in report.items():
        # Get the otu info for the sequence id.
        otu_id = job.params["sequence_otu_map"][ref_id]
        otu_version = job.params["manifest"][otu_id]

        hit["id"] = ref_id

        # Attach "otu" (id, version) to the hit.
        hit["otu"] = {
            "version": otu_version,
            "id": otu_id
        }

        # Get the coverage for the sequence.
        hit_coverage = job.intermediate["coverage"][ref_id]

        # Attach coverage list to hit dict.
        hit["align"] = hit_coverage

        # Calculate coverage and attach to hit.
        hit["coverage"] = round(1 - hit_coverage.count(0) / len(hit_coverage), 3)

        # Calculate depth and attach to hit.
        hit["depth"] = round(sum(hit_coverage) / len(hit_coverage))

        job.results["results"].append(hit)


async def import_results(self):
    """
    Commits the results to the database. Data includes the output of Pathoscope, final mapped read count,
    and viral genome coverage maps.

    Once the import is complete, :meth:`cleanup_index_files` is called to remove
    any otu indexes that may become unused when this analysis completes.

    TODO: Should be incorporated into a generic end-of-workflow result import functionality. This is going to require
          of rethinking and restructuring of analysis documents in the database.

    """
    analysis_id = self.params["analysis_id"]
    sample_id = self.params["sample_id"]

    # Pop the main results from `self.results`, leaving small data (eg. read_count) that will easily fit in the DB
    # document.
    results = self.results.pop("results")

    # Update the database document with the small data.
    await self.db.analyses.update_one({"_id": analysis_id}, {
        "$set": self.results
    })

    await virtool.jobs.analysis.set_analysis_results(
        self.db,
        analysis_id,
        self.params["analysis_path"],
        results
    )

    await virtool.samples.db.recalculate_workflow_tags(self.db, sample_id)


def run_patho(vta_path, reassigned_path):
    """
    Run Pathoscope. This function is CPU-intensive and should be run in a separate process.

    TODO: Move to workflow-pathoscope.

    :param vta_path:
    :param reassigned_path:
    :return:
    """
    u, nu, refs, reads = virtool.pathoscope.build_matrix(vta_path)

    best_hit_initial_reads, best_hit_initial, level_1_initial, level_2_initial = virtool.pathoscope.compute_best_hit(
        u,
        nu,
        refs,
        reads
    )

    init_pi, pi, _, nu = virtool.pathoscope.em(u, nu, refs, 50, 1e-7, 0, 0)

    best_hit_final_reads, best_hit_final, level_1_final, level_2_final = virtool.pathoscope.compute_best_hit(
        u,
        nu,
        refs,
        reads
    )

    virtool.pathoscope.rewrite_align(u, nu, vta_path, 0.01, reassigned_path)

    return (
        best_hit_initial_reads,
        best_hit_initial,
        level_1_initial,
        level_2_initial,
        best_hit_final_reads,
        best_hit_final,
        level_1_final,
        level_2_final,
        init_pi,
        pi,
        refs,
        reads
    )


def create():
    job = virtool.jobs.job.Job()

    job.on_startup = [
        virtool.jobs.analysis.check_db
    ]

    job.steps = [
        virtool.jobs.analysis.make_analysis_dir,
        virtool.jobs.analysis.prepare_reads,
        map_default_isolates,
        generate_isolate_fasta,
        build_isolate_index,
        map_isolates,
        map_subtraction,
        subtract_mapping,
        pathoscope,
        virtool.jobs.analysis.upload,
        import_results
    ]

    job.on_cleanup = [
        virtool.jobs.analysis.delete_analysis,
        virtool.jobs.analysis.delete_cache
    ]

    return job
